% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mmitboost.R
\name{mmitboost}
\alias{mmitboost}
\title{Adaboost for the Max Margin Interval Tree}
\usage{
mmitboost(target.mat, feature.mat, max_depth = Inf, margin = 0,
  loss = "hinge", min_sample = 1, weights = rep(1L,
  nrow(feature.mat))/seq(1L, nrow(feature.mat), 1), M = 10)
}
\arguments{
\item{target.mat}{The response variable of the model}

\item{feature.mat}{a data frame containing the feature variables in the model.}

\item{max_depth}{The maximum depth criteia}

\item{margin}{margin paramaters}

\item{loss}{The type of loss; (\code{"hinge"}, \code{"square"})}

\item{min_sample}{The minimum number of sample required}

\item{weights}{An importance weight for each learning example, (default = 1)}

\item{M}{An integer for number of iterations of weight update.}
}
\value{
Predicted Training Data
}
\description{
Learning adaptive boosting for the Max Margin Interval Tree
}
\examples{
library(mmit)
target.mat <- rbind(
  c(0,1), c(0,1), c(0,1),
  c(2,3), c(2,3), c(2,3))

feature.mat <- rbind(
  c(1,0,0), c(1,1,0), c(1,2,0),
  c(1,3,0), c(1,4,0), c(1,5,0))

colnames(feature.mat) <- c("a", "b", "c")
feature.mat <- data.frame(feature.mat)


out <- mmitboost(target.mat, feature.mat)

}
\author{
Toby Dylan Hocking, Alexandre Drouin, Torsten Hothorn, Parismita Das
}
